{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_A = pd.read_csv('data/mid_nm.csv', sep=\",\")\n",
    "df_A = pd.DataFrame(data_A, columns=data_A.keys())\n",
    "\n",
    "data_B = pd.read_csv('data/mitm.csv', sep=\",\")\n",
    "df_B = pd.DataFrame(data_B, columns=data_B.keys())\n",
    "\n",
    "data_C = pd.read_csv('data/modbus_Query_Flooding.csv', sep=\",\")\n",
    "df_C = pd.DataFrame(data_C, columns=data_C.keys())\n",
    "\n",
    "data_D = pd.read_csv('data/normal_file.csv', sep=\",\")\n",
    "df_D = pd.DataFrame(data_D, columns=data_D.keys())\n",
    "\n",
    "data_E = pd.read_csv('data/pingFloodDDoS.csv', sep=\",\")\n",
    "df_E = pd.DataFrame(data_E, columns=data_E.keys())\n",
    "\n",
    "data_F = pd.read_csv('data/tcpSYNFloodDDoS.csv', sep=\",\")\n",
    "df_F = pd.DataFrame(data_F, columns=data_F.keys())\n",
    "\n",
    "res = pd.concat([df_A, df_B, df_C, df_D, df_E,df_F])\n",
    "\n",
    "res.to_csv(\"full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 2474127\n",
      "test data: 1649419\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "full_data = pd.read_csv(\"full.csv\", sep=\",\")\n",
    "full_data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "df_full = pd.DataFrame(full_data, columns=full_data.keys())\n",
    "\n",
    "df_shuffed = df_full.iloc[np.random.permutation(df_full.index)].reset_index(drop=True)\n",
    "\n",
    "full_len = len(df_shuffed)\n",
    "train_len = int(full_len * 0.6) \n",
    "\n",
    "train_df = df_shuffed.iloc[:train_len,:]\n",
    "test_df = df_shuffed.iloc[train_len:,:]\n",
    "\n",
    "print(\"train data: \" + str(len(train_df)))\n",
    "print(\"test data: \" + str(len(test_df)))\n",
    "\n",
    "train_df.to_csv(\"train.csv\")\n",
    "test_df.to_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 2474127\n",
      "test data: 1649419\n",
      "Index(['ICMP code_7bit', 'n_same_src_ip', 'n_same_dst_ip',\n",
      "       'n_same_src_ip_port', 'n_same_dst_ip_port', 'n_dst_ip_src_ip_count',\n",
      "       'n_src_dst_ip_src_port_count', 'n_src_dst_ip_dst_port_count',\n",
      "       'n_src_ip_data_len', 'n_dst_ip_data_len', 'n_src_ip_ICMP_count',\n",
      "       'n_src_ip_SYN_count', 'n_dst_ip_ICMP_count', 'n_dst_ip_SYN_count',\n",
      "       'attack_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv', sep=\",\")\n",
    "test_data = pd.read_csv('test.csv', sep=\",\")\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=train_data.keys())\n",
    "test_df = pd.DataFrame(test_data, columns=test_data.keys())\n",
    "\n",
    "print(\"train data: \" + str(len(train_df)))\n",
    "print(\"test data: \" + str(len(test_df)))\n",
    "\n",
    "print(test_data.keys()[28:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class Data_Load:\n",
    "    def __init__(self, test_file_loc, train_file_loc, extract_list, Y_loc=41):\n",
    "        self.extract_list = extract_list\n",
    "        test_data = pd.read_csv(test_file_loc, sep=\",\")\n",
    "        test_data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "        test_data = test_data.iloc[np.random.permutation(test_data.index)].reset_index(drop=True)\n",
    "        train_data = pd.read_csv(train_file_loc, sep=\",\")\n",
    "        train_data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "        train_data = train_data.iloc[np.random.permutation(train_data.index)].reset_index(drop=True)\n",
    "        \n",
    "        self.X_test = test_data.iloc[:, extract_list]\n",
    "        self.X_train = train_data.iloc[:, extract_list]\n",
    "        self.Y_test = test_data.iloc[:, [Y_loc]]\n",
    "        self.Y_train = train_data.iloc[:, [Y_loc]]\n",
    "        \n",
    "        self.input_len = len(extract_list)\n",
    "        \n",
    "l1 = [] #full data\n",
    "for i in range(41):\n",
    "    l1.append(i)\n",
    "l2 = [0, 1]+ l1[28:] #no flag bits\n",
    "l3 = l1[28:] #only relative info\n",
    "l4 = l1[:34] + [36] + [39, 40] # sub some same src_ip info\n",
    "'''\n",
    "l4:\n",
    "n초간 동일 src_ip에서 보낸 data 길이 총합(bytes)\n",
    "n초간 동일 src_ip에서 보낸 ICMP 패킷 수\n",
    "n초간 동일 src_ip에서 보낸 SYN 패킷 수\n",
    "\n",
    "제거\n",
    "'''\n",
    "    \n",
    "data1 = Data_Load(\"test.csv\", \"train.csv\", l1)\n",
    "\n",
    "data2 = Data_Load(\"test.csv\", \"train.csv\", l2)\n",
    "\n",
    "data3 = Data_Load(\"test.csv\", \"train.csv\", l3)\n",
    "\n",
    "data4 = Data_Load(\"test.csv\", \"train.csv\", l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEXON\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEXON\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEXON\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEXON\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class SVM_Model:\n",
    "    def __init__(self, input_len, X_train, X_test, Y_train, Y_test, extract_list):\n",
    "        self.extract_list = extract_list\n",
    "        self.model = SVC(kernel='rbf', C=8, gamma=0.1, max_iter=500)\n",
    "        self.input_len = input_len\n",
    "        \n",
    "        self.X_train= X_train.to_numpy()\n",
    "        self.X_test= X_test.to_numpy()\n",
    "        self.Y_train= Y_train.to_numpy().flatten()\n",
    "        self.Y_test= Y_test.to_numpy().flatten()\n",
    "        \n",
    "        self.train_time = 0\n",
    "        self.test_time = 0\n",
    "        self.acc = 0\n",
    "        self.f1 = 0\n",
    "        self.prec = 0\n",
    "        self.recall = 0\n",
    "        \n",
    "    def train(self):\n",
    "        train_time_start = time.time()\n",
    "        self.model.fit(self.X_train, self.Y_train)\n",
    "        train_time_end = time.time()\n",
    "        \n",
    "        self.train_time = train_time_end - train_time_start\n",
    "        \n",
    "    def test(self):\n",
    "        test_time_start = time.time()\n",
    "        y_pred  = self.model.predict(self.X_test)\n",
    "        test_time_end = time.time()\n",
    "        \n",
    "        self.test_time = test_time_end - test_time_start\n",
    "        self.acc = np.mean(y_pred == self.Y_test)\n",
    "        self.f1 = f1_score(self.Y_test, y_pred, average='micro')\n",
    "        self.prec = precision_score(self.Y_test, y_pred, average='micro')\n",
    "        self.recall = recall_score(self.Y_test, y_pred, average='micro')\n",
    "        print(\"prediction accuracy: {:.2f}\".format(self.acc)) # 예측 정확도\n",
    "        \n",
    "    def save(self):\n",
    "        tm = time.localtime()\n",
    "        tm_string = time.strftime('%Y-%m-%d-%H_%M_%S', tm)\n",
    "        f = open('SVM_Model'+tm_string+'.txt', 'w')\n",
    "        f.write('train time: ' + str(self.train_time)+'\\n')\n",
    "        f.write('test time: ' + str(self.test_time)+'\\n')\n",
    "        f.write('acc: ' + str(self.acc)+'\\n')\n",
    "        f.write('f1: ' + str(self.f1)+'\\n')\n",
    "        f.write('prec: ' + str(self.prec)+'\\n')\n",
    "        f.write('recall: ' + str(self.recall)+'\\n')\n",
    "        f.write('extract_list: ' + str(self.extract_list)+'\\n')\n",
    "        \n",
    "        dump(self.model, 'SVM_Model'+tm_string+'.pkl')\n",
    "        \n",
    "svm1 = SVM_Model(data1.input_len, data1.X_train, data1.X_test, data1.Y_train, data1.Y_test, data1.extract_list)\n",
    "svm1.train()\n",
    "svm1.test()\n",
    "svm1.save()\n",
    "\n",
    "svm2 = SVM_Model(data2.input_len, data2.X_train, data2.X_test, data2.Y_train, data2.Y_test, data2.extract_list)\n",
    "svm2.train()\n",
    "svm2.test()\n",
    "svm2.save()\n",
    "\n",
    "svm3 = SVM_Model(data3.input_len, data3.X_train, data3.X_test, data3.Y_train, data3.Y_test, data3.extract_list)\n",
    "svm3.train()\n",
    "svm3.test()\n",
    "svm3.save()\n",
    "\n",
    "svm4 = SVM_Model(data4.input_len, data4.X_train, data4.X_test, data4.Y_train, data4.Y_test, data4.extract_list)\n",
    "svm4.train()\n",
    "svm4.test()\n",
    "svm4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class K_NN_Model:\n",
    "    def __init__(self, input_len, X_train, X_test, Y_train, Y_test, extract_list):\n",
    "        self.extract_list = extract_list\n",
    "        #weights: \"uniform\" or \"distance\"\n",
    "        self.model = KNeighborsClassifier(n_neighbors = 5, weights = \"distance\")\n",
    "        self.input_len = input_len\n",
    "        \n",
    "        self.X_train= X_train.to_numpy()\n",
    "        self.X_test= X_test.to_numpy()\n",
    "        self.Y_train= Y_train.to_numpy().flatten()\n",
    "        self.Y_test= Y_test.to_numpy().flatten()\n",
    "        \n",
    "        self.train_time = 0\n",
    "        self.test_time = 0\n",
    "        self.acc = 0\n",
    "        self.f1 = 0\n",
    "        self.prec = 0\n",
    "        self.recall = 0\n",
    "        \n",
    "    def train(self):\n",
    "        train_time_start = time.time()\n",
    "        self.model.fit(self.X_train, self.Y_train)\n",
    "        train_time_end = time.time()\n",
    "        \n",
    "        self.train_time = train_time_end - train_time_start\n",
    "        \n",
    "    def test(self):\n",
    "        test_time_start = time.time()\n",
    "        y_pred  = self.model.predict(self.X_test)\n",
    "        test_time_end = time.time()\n",
    "        \n",
    "        self.test_time = test_time_end - test_time_start\n",
    "        self.acc = np.mean(y_pred == self.Y_test)\n",
    "        self.f1 = f1_score(self.Y_test, y_pred, average='micro')\n",
    "        self.prec = precision_score(self.Y_test, y_pred, average='micro')\n",
    "        self.recall = recall_score(self.Y_test, y_pred, average='micro')\n",
    "        print(\"prediction accuracy: {:.2f}\".format(self.acc)) # 예측 정확도\n",
    "        \n",
    "    def save(self):\n",
    "        tm = time.localtime()\n",
    "        tm_string = time.strftime('%Y-%m-%d-%H_%M_%S', tm)\n",
    "        f = open('K_NN_Model'+tm_string+'.txt', 'w')\n",
    "        f.write('train time: ' + str(self.train_time)+'\\n')\n",
    "        f.write('test time: ' + str(self.test_time)+'\\n')\n",
    "        f.write('acc: ' + str(self.acc)+'\\n')\n",
    "        f.write('f1: ' + str(self.f1)+'\\n')\n",
    "        f.write('prec: ' + str(self.prec)+'\\n')\n",
    "        f.write('recall: ' + str(self.recall)+'\\n')\n",
    "        f.write('extract_list: ' + str(self.extract_list)+'\\n')\n",
    "        \n",
    "        dump(self.model, 'K_NN_Model'+tm_string+'.pkl')\n",
    "        \n",
    "        \n",
    "knn1 = K_NN_Model(data1.input_len, data1.X_train, data1.X_test, data1.Y_train, data1.Y_test, data1.extract_list)\n",
    "knn1.train()\n",
    "#knn1.test()\n",
    "knn1.save()\n",
    "\n",
    "knn2 = K_NN_Model(data2.input_len, data2.X_train, data2.X_test, data2.Y_train, data2.Y_test, data2.extract_list)\n",
    "knn2.train()\n",
    "#knn2.test()\n",
    "knn2.save()\n",
    "\n",
    "knn3 = K_NN_Model(data3.input_len, data3.X_train, data3.X_test, data3.Y_train, data3.Y_test, data3.extract_list)\n",
    "knn3.train()\n",
    "#knn3.test()\n",
    "knn3.save()\n",
    "\n",
    "knn4 = K_NN_Model(data4.input_len, data4.X_train, data4.X_test, data4.Y_train, data4.Y_test, data4.extract_list)\n",
    "knn4.train()\n",
    "#knn4.test()\n",
    "knn4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.99\n",
      "prediction accuracy: 0.99\n",
      "prediction accuracy: 0.99\n",
      "prediction accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class Random_Forest_Model:\n",
    "    def __init__(self, input_len, X_train, X_test, Y_train, Y_test, extract_list):\n",
    "        self.extract_list = extract_list\n",
    "        self.model = RandomForestClassifier(n_estimators=50)\n",
    "        self.input_len = input_len\n",
    "        \n",
    "        self.X_train= X_train.to_numpy()\n",
    "        self.X_test= X_test.to_numpy()\n",
    "        self.Y_train= Y_train.to_numpy().flatten()\n",
    "        self.Y_test= Y_test.to_numpy().flatten()\n",
    "        \n",
    "        self.train_time = 0\n",
    "        self.test_time = 0\n",
    "        self.acc = 0\n",
    "        self.f1 = 0\n",
    "        self.prec = 0\n",
    "        self.recall = 0\n",
    "        \n",
    "    def train(self):\n",
    "        train_time_start = time.time()\n",
    "        self.model.fit(self.X_train, self.Y_train)\n",
    "        train_time_end = time.time()\n",
    "        \n",
    "        self.train_time = train_time_end - train_time_start\n",
    "        \n",
    "    def test(self):\n",
    "        test_time_start = time.time()\n",
    "        y_pred  = self.model.predict(self.X_test)\n",
    "        test_time_end = time.time()\n",
    "        \n",
    "        self.test_time = test_time_end - test_time_start\n",
    "        self.acc = np.mean(y_pred == self.Y_test)\n",
    "        self.f1 = f1_score(self.Y_test, y_pred, average='micro')\n",
    "        self.prec = precision_score(self.Y_test, y_pred, average='micro')\n",
    "        self.recall = recall_score(self.Y_test, y_pred, average='micro')\n",
    "        print(\"prediction accuracy: {:.2f}\".format(self.acc)) # 예측 정확도\n",
    "        \n",
    "    def save(self):\n",
    "        tm = time.localtime()\n",
    "        tm_string = time.strftime('%Y-%m-%d-%H_%M_%S', tm)\n",
    "        f = open('Random_Forest_Model'+tm_string+'.txt', 'w')\n",
    "        f.write('train time: ' + str(self.train_time)+'\\n')\n",
    "        f.write('test time: ' + str(self.test_time)+'\\n')\n",
    "        f.write('acc: ' + str(self.acc)+'\\n')\n",
    "        f.write('f1: ' + str(self.f1)+'\\n')\n",
    "        f.write('prec: ' + str(self.prec)+'\\n')\n",
    "        f.write('recall: ' + str(self.recall)+'\\n')\n",
    "        f.write('extract_list: ' + str(self.extract_list)+'\\n')\n",
    "        \n",
    "        dump(self.model, 'Random_Forest_Model'+tm_string+'.pkl')\n",
    "\n",
    "\n",
    "rfm1 = Random_Forest_Model(data1.input_len, data1.X_train, data1.X_test, data1.Y_train, data1.Y_test, data1.extract_list)\n",
    "rfm1.train()\n",
    "rfm1.test()\n",
    "rfm1.save()\n",
    "\n",
    "rfm2 = Random_Forest_Model(data2.input_len, data2.X_train, data2.X_test, data2.Y_train, data2.Y_test, data2.extract_list)\n",
    "rfm2.train()\n",
    "rfm2.test()\n",
    "rfm2.save()\n",
    "\n",
    "rfm3 = Random_Forest_Model(data3.input_len, data3.X_train, data3.X_test, data3.Y_train, data3.Y_test, data3.extract_list)\n",
    "rfm3.train()\n",
    "rfm3.test()\n",
    "rfm3.save()\n",
    "\n",
    "rfm4 = Random_Forest_Model(data4.input_len, data4.X_train, data4.X_test, data4.Y_train, data4.Y_test, data4.extract_list)\n",
    "rfm4.train()\n",
    "rfm4.test()\n",
    "rfm4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.58\n",
      "prediction accuracy: 0.03\n",
      "prediction accuracy: 0.01\n",
      "prediction accuracy: 0.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class K_Means_Model:\n",
    "    def __init__(self, input_len, X_train, X_test, Y_train, Y_test, extract_list):\n",
    "        self.extract_list = extract_list\n",
    "        self.model = KMeans(n_clusters=5)\n",
    "        self.input_len = input_len\n",
    "        \n",
    "        self.X_train= X_train.to_numpy()\n",
    "        self.X_test= X_test.to_numpy()\n",
    "        self.Y_train= Y_train.to_numpy().flatten() #통일성을 위해 있는 더미\n",
    "        self.Y_test= Y_test.to_numpy().flatten()\n",
    "        \n",
    "        self.train_time = 0\n",
    "        self.test_time = 0\n",
    "        self.acc = 0\n",
    "        self.f1 = 0\n",
    "        self.prec = 0\n",
    "        self.recall = 0\n",
    "        \n",
    "    def train(self):\n",
    "        train_time_start = time.time()\n",
    "        self.model.fit(self.X_train)\n",
    "        train_time_end = time.time()\n",
    "        \n",
    "        self.train_time = train_time_end - train_time_start\n",
    "        \n",
    "    def test(self):\n",
    "        test_time_start = time.time()\n",
    "        y_pred  = self.model.predict(self.X_test)\n",
    "        test_time_end = time.time()\n",
    "        \n",
    "        self.test_time = test_time_end - test_time_start\n",
    "        self.acc = np.mean(y_pred == self.Y_test)\n",
    "        self.f1 = f1_score(self.Y_test, y_pred, average='micro')\n",
    "        self.prec = precision_score(self.Y_test, y_pred, average='micro')\n",
    "        self.recall = recall_score(self.Y_test, y_pred, average='micro')\n",
    "        print(\"prediction accuracy: {:.2f}\".format(self.acc)) # 예측 정확도\n",
    "        \n",
    "    def save(self):\n",
    "        tm = time.localtime()\n",
    "        tm_string = time.strftime('%Y-%m-%d-%H_%M_%S', tm)\n",
    "        f = open('K_Means_Model'+tm_string+'.txt', 'w')\n",
    "        f.write('train time: ' + str(self.train_time)+'\\n')\n",
    "        f.write('test time: ' + str(self.test_time)+'\\n')\n",
    "        f.write('acc: ' + str(self.acc)+'\\n')\n",
    "        f.write('f1: ' + str(self.f1)+'\\n')\n",
    "        f.write('prec: ' + str(self.prec)+'\\n')\n",
    "        f.write('recall: ' + str(self.recall)+'\\n')\n",
    "        f.write('extract_list: ' + str(self.extract_list)+'\\n')\n",
    "        \n",
    "        dump(self.model, 'K_Means_Model'+tm_string+'.pkl')\n",
    "        \n",
    "kmm1 = K_Means_Model(data1.input_len, data1.X_train, data1.X_test, data1.Y_train, data1.Y_test, data1.extract_list)\n",
    "kmm1.train()\n",
    "kmm1.test()\n",
    "kmm1.save()\n",
    "\n",
    "kmm2 = K_Means_Model(data2.input_len, data2.X_train, data2.X_test, data2.Y_train, data2.Y_test, data2.extract_list)\n",
    "kmm2.train()\n",
    "kmm2.test()\n",
    "kmm2.save()\n",
    "\n",
    "kmm3 = K_Means_Model(data3.input_len, data3.X_train, data3.X_test, data3.Y_train, data3.Y_test, data3.extract_list)\n",
    "kmm3.train()\n",
    "kmm3.test()\n",
    "kmm3.save()\n",
    "\n",
    "kmm4 = K_Means_Model(data4.input_len, data4.X_train, data4.X_test, data4.Y_train, data4.Y_test, data4.extract_list)\n",
    "kmm4.train()\n",
    "kmm4.test()\n",
    "kmm4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.99\n",
      "prediction accuracy: 0.99\n",
      "prediction accuracy: 0.99\n",
      "prediction accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import time\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class DT_Model:\n",
    "    def __init__(self, input_len, X_train, X_test, Y_train, Y_test, extract_list):\n",
    "        self.extract_list = extract_list\n",
    "        self.model = tree.DecisionTreeClassifier()\n",
    "        self.input_len = input_len\n",
    "        \n",
    "        self.X_train= X_train.to_numpy()\n",
    "        self.X_test= X_test.to_numpy()\n",
    "        self.Y_train= Y_train.to_numpy().flatten()\n",
    "        self.Y_test= Y_test.to_numpy().flatten()\n",
    "        \n",
    "        self.train_time = 0\n",
    "        self.test_time = 0\n",
    "        self.acc = 0\n",
    "        self.f1 = 0\n",
    "        self.prec = 0\n",
    "        self.recall = 0\n",
    "        \n",
    "    def train(self):\n",
    "        train_time_start = time.time()\n",
    "        self.model.fit(self.X_train, self.Y_train)\n",
    "        train_time_end = time.time()\n",
    "\n",
    "        self.train_time = train_time_end - train_time_start\n",
    "        \n",
    "    def test(self):\n",
    "        test_time_start = time.time()\n",
    "        y_pred  = self.model.predict(self.X_test)\n",
    "        test_time_end = time.time()\n",
    "        \n",
    "        self.test_time = test_time_end - test_time_start\n",
    "        self.acc = np.mean(y_pred == self.Y_test)\n",
    "        self.f1 = f1_score(self.Y_test, y_pred, average='micro')\n",
    "        self.prec = precision_score(self.Y_test, y_pred, average='micro')\n",
    "        self.recall = recall_score(self.Y_test, y_pred, average='micro')\n",
    "        print(\"prediction accuracy: {:.2f}\".format(self.acc)) # 예측 정확도\n",
    "        \n",
    "    def save(self):\n",
    "        tm = time.localtime()\n",
    "        tm_string = time.strftime('%Y-%m-%d-%H_%M_%S', tm)\n",
    "        f = open('DT_Model'+tm_string+'.txt', 'w')\n",
    "        f.write('train time: ' + str(self.train_time)+'\\n')\n",
    "        f.write('test time: ' + str(self.test_time)+'\\n')\n",
    "        f.write('acc: ' + str(self.acc)+'\\n')\n",
    "        f.write('f1: ' + str(self.f1)+'\\n')\n",
    "        f.write('prec: ' + str(self.prec)+'\\n')\n",
    "        f.write('recall: ' + str(self.recall)+'\\n')\n",
    "        f.write('extract_list: ' + str(self.extract_list)+'\\n')\n",
    "        \n",
    "        dump(self.model, 'DT_Model'+tm_string+'.pkl')\n",
    "        \n",
    "dtm1 = DT_Model(data1.input_len, data1.X_train, data1.X_test, data1.Y_train, data1.Y_test, data1.extract_list)\n",
    "dtm1.train()\n",
    "dtm1.test()\n",
    "dtm1.save()\n",
    "\n",
    "dtm2 = DT_Model(data2.input_len, data2.X_train, data2.X_test, data2.Y_train, data2.Y_test, data2.extract_list)\n",
    "dtm2.train()\n",
    "dtm2.test()\n",
    "dtm2.save()\n",
    "\n",
    "dtm3 = DT_Model(data3.input_len, data3.X_train, data3.X_test, data3.Y_train, data3.Y_test, data3.extract_list)\n",
    "dtm3.train()\n",
    "dtm3.test()\n",
    "dtm3.save()\n",
    "\n",
    "dtm4 = DT_Model(data4.input_len, data4.X_train, data4.X_test, data4.Y_train, data4.Y_test, data4.extract_list)\n",
    "dtm4.train()\n",
    "dtm4.test()\n",
    "dtm4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "class DNN_Model:\n",
    "    def __init__(self, input_len, X_train, X_test, Y_train, Y_test, extract_list):\n",
    "        self.extract_list = extract_list\n",
    "        self.input_len = input_len\n",
    "        \n",
    "        self.X_train= X_train.to_numpy()\n",
    "        self.X_test= X_test.to_numpy()\n",
    "        self.Y_train= tf.keras.utils.to_categorical(Y_train.to_numpy().flatten())\n",
    "        self.Y_test= tf.keras.utils.to_categorical(Y_test.to_numpy().flatten())\n",
    "        \n",
    "        #need to change shape\n",
    "        self.model = keras.Sequential([\n",
    "            layers.Dense(64, activation='relu', input_shape=[self.input_len]),\n",
    "            layers.Dense(48, activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(5, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(optimizer='adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "        \n",
    "        self.train_time = 0\n",
    "        self.test_time = 0\n",
    "        self.acc = 0\n",
    "        self.f1 = 0\n",
    "        self.prec = 0\n",
    "        self.recall = 0\n",
    "        \n",
    "    def train(self):\n",
    "        train_time_start = time.time()\n",
    "        self.model.fit(self.X_train,\n",
    "                       self.Y_train,  \n",
    "                       epochs=5)\n",
    "        train_time_end = time.time()\n",
    "        \n",
    "        self.train_time = train_time_end - train_time_start\n",
    "        \n",
    "    def test(self):\n",
    "        test_time_start = time.time()\n",
    "        test_loss, test_acc, test_f1, test_prec, test_recall = self.model.evaluate(self.X_test, self.Y_test, verbose=2)\n",
    "        test_time_end = time.time()\n",
    "        \n",
    "        self.test_time = test_time_end - test_time_start\n",
    "        self.acc = test_acc\n",
    "        self.f1 = test_f1\n",
    "        self.prec = test_prec\n",
    "        self.recall = test_recall\n",
    "        print(\"prediction accuracy: {:.2f}\".format(test_acc)) # 예측 정확도\n",
    "        \n",
    "    def save(self):\n",
    "        tm = time.localtime()\n",
    "        tm_string = time.strftime('%Y-%m-%d-%H_%M_%S', tm)\n",
    "        f = open('DNN_Model'+tm_string+'.txt', 'w')\n",
    "        f.write('train time: ' + str(self.train_time)+'\\n')\n",
    "        f.write('test time: ' + str(self.test_time)+'\\n')\n",
    "        f.write('acc: ' + str(self.acc)+'\\n')\n",
    "        f.write('f1: ' + str(self.f1)+'\\n')\n",
    "        f.write('prec: ' + str(self.prec)+'\\n')\n",
    "        f.write('recall: ' + str(self.recall)+'\\n')\n",
    "        f.write('extract_list: ' + str(self.extract_list)+'\\n')\n",
    "        \n",
    "        self.model.save(\"DNN_Model\"+tm_string)\n",
    "        \n",
    "        \n",
    "dnn1 = DNN_Model(data1.input_len, data1.X_train, data1.X_test, data1.Y_train, data1.Y_test, data1.extract_list)\n",
    "dnn1.train()\n",
    "dnn1.test()\n",
    "dnn1.save()\n",
    "\n",
    "dnn2 = DNN_Model(data2.input_len, data2.X_train, data2.X_test, data2.Y_train, data2.Y_test, data2.extract_list)\n",
    "dnn2.train()\n",
    "dnn2.test()\n",
    "dnn2.save()\n",
    "\n",
    "dnn3 = DNN_Model(data3.input_len, data3.X_train, data3.X_test, data3.Y_train, data3.Y_test, data3.extract_list)\n",
    "dnn3.train()\n",
    "dnn3.test()\n",
    "dnn3.save()\n",
    "\n",
    "dnn4 = DNN_Model(data4.input_len, data4.X_train, data4.X_test, data4.Y_train, data4.Y_test, data4.extract_list)\n",
    "dnn4.train()\n",
    "dnn4.test()\n",
    "dnn4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 54s 693us/step - loss: 0.4848 - val_loss: 0.4840\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 54s 703us/step - loss: 0.4833 - val_loss: 0.4839\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 56s 719us/step - loss: 0.4824 - val_loss: 0.4828\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 54s 700us/step - loss: 0.4821 - val_loss: 0.4826\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 57s 734us/step - loss: 0.4821 - val_loss: 0.4826\n",
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 45s 567us/step - loss: 0.0485 - accuracy: 0.9853 - f1_m: 0.9844 - precision_m: 0.9856 - recall_m: 0.9835\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 44s 568us/step - loss: 0.0410 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 42s 547us/step - loss: 0.0408 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 43s 551us/step - loss: 0.0409 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 43s 557us/step - loss: 0.0409 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "51545/51545 - 18s - loss: 0.0401 - accuracy: 0.9866 - f1_m: 0.9866 - precision_m: 0.9867 - recall_m: 0.9866\n",
      "prediction accuracy: 0.99\n",
      "INFO:tensorflow:Assets written to: Encoder_Model2021-06-02-19_27_44\\assets\n",
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 53s 682us/step - loss: 1.3198 - val_loss: 1.3194\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 52s 679us/step - loss: 1.3178 - val_loss: 1.3197\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 52s 676us/step - loss: 1.3176 - val_loss: 1.3192\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 53s 679us/step - loss: 1.3175 - val_loss: 1.3191\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 53s 682us/step - loss: 1.3175 - val_loss: 1.3191\n",
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 43s 546us/step - loss: 0.0450 - accuracy: 0.9855 - f1_m: 0.9854 - precision_m: 0.9862 - recall_m: 0.9850\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 42s 549us/step - loss: 0.0411 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 42s 544us/step - loss: 0.0412 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 42s 547us/step - loss: 0.0410 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 42s 547us/step - loss: 0.0412 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "51545/51545 - 17s - loss: 0.0412 - accuracy: 0.9867 - f1_m: 0.9867 - precision_m: 0.9867 - recall_m: 0.9867\n",
      "prediction accuracy: 0.99\n",
      "INFO:tensorflow:Assets written to: Encoder_Model2021-06-02-19_35_58\\assets\n",
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 52s 672us/step - loss: 1.4396 - val_loss: 1.4388\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 52s 677us/step - loss: 1.4370 - val_loss: 1.4387\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 52s 670us/step - loss: 1.4369 - val_loss: 1.4385\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 51s 663us/step - loss: 1.4368 - val_loss: 1.4385\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 52s 671us/step - loss: 1.4368 - val_loss: 1.4385\n",
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 42s 537us/step - loss: 0.0445 - accuracy: 0.9857 - f1_m: 0.9856 - precision_m: 0.9860 - recall_m: 0.9854\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 42s 548us/step - loss: 0.0409 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 42s 538us/step - loss: 0.0408 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 42s 541us/step - loss: 0.0408 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 42s 538us/step - loss: 0.0408 - accuracy: 0.9865 - f1_m: 0.9865 - precision_m: 0.9865 - recall_m: 0.9865\n",
      "51545/51545 - 17s - loss: 0.0399 - accuracy: 0.9867 - f1_m: 0.9867 - precision_m: 0.9867 - recall_m: 0.9867\n",
      "prediction accuracy: 0.99\n",
      "INFO:tensorflow:Assets written to: Encoder_Model2021-06-02-19_44_06\\assets\n",
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 54s 693us/step - loss: 0.4355 - val_loss: 0.4340\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 53s 690us/step - loss: 0.4332 - val_loss: 0.4333\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 53s 691us/step - loss: 0.4328 - val_loss: 0.4333\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 53s 683us/step - loss: 0.4328 - val_loss: 0.4333\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 53s 689us/step - loss: 0.4328 - val_loss: 0.4333\n",
      "Epoch 1/5\n",
      "77317/77317 [==============================] - 42s 540us/step - loss: 0.0507 - accuracy: 0.9841 - f1_m: 0.9839 - precision_m: 0.9849 - recall_m: 0.9835\n",
      "Epoch 2/5\n",
      "77317/77317 [==============================] - 42s 543us/step - loss: 0.0419 - accuracy: 0.9864 - f1_m: 0.9864 - precision_m: 0.9864 - recall_m: 0.9864\n",
      "Epoch 3/5\n",
      "77317/77317 [==============================] - 42s 541us/step - loss: 0.0417 - accuracy: 0.9864 - f1_m: 0.9864 - precision_m: 0.9864 - recall_m: 0.9864\n",
      "Epoch 4/5\n",
      "77317/77317 [==============================] - 42s 540us/step - loss: 0.0416 - accuracy: 0.9864 - f1_m: 0.9864 - precision_m: 0.9864 - recall_m: 0.9864\n",
      "Epoch 5/5\n",
      "77317/77317 [==============================] - 42s 541us/step - loss: 0.0413 - accuracy: 0.9864 - f1_m: 0.9864 - precision_m: 0.9864 - recall_m: 0.9864\n",
      "51545/51545 - 17s - loss: 0.0411 - accuracy: 0.9866 - f1_m: 0.9866 - precision_m: 0.9866 - recall_m: 0.9866\n",
      "prediction accuracy: 0.99\n",
      "INFO:tensorflow:Assets written to: Encoder_Model2021-06-02-19_52_22\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "import time\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, input_len):\n",
    "        self.input_len = input_len\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(32, activation='relu', input_shape=[self.input_len]),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(8, activation='relu')\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(self.input_len, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "class Encoder_Model:\n",
    "    def __init__(self, input_len, X_train, X_test, Y_train, Y_test, extract_list):\n",
    "        self.extract_list = extract_list\n",
    "        self.input_len = input_len\n",
    "        \n",
    "        self.X_train= X_train.to_numpy()\n",
    "        self.X_test= X_test.to_numpy()\n",
    "        self.Y_train= tf.keras.utils.to_categorical(Y_train.to_numpy().flatten())\n",
    "        self.Y_test= tf.keras.utils.to_categorical(Y_test.to_numpy().flatten())\n",
    "        \n",
    "        self.autoencoder = Autoencoder(self.input_len)\n",
    "        self.model = None\n",
    "        \n",
    "        self.autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "        \n",
    "        self.train_time = 0\n",
    "        self.test_time = 0\n",
    "        self.acc = 0\n",
    "        \n",
    "    def train(self):\n",
    "        train_time_start = time.time()\n",
    "        self.autoencoder.fit(self.X_train,\n",
    "                             self.X_train,  \n",
    "                             validation_data=(self.X_test, self.X_test),\n",
    "                             epochs=5)\n",
    "        \n",
    "        self.model = tf.keras.Sequential([\n",
    "            self.autoencoder.encoder,\n",
    "            layers.Dense(8, activation='relu'),\n",
    "            layers.Dense(5, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(optimizer='adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "        \n",
    "        self.model.fit(self.X_train,\n",
    "                       self.Y_train,  \n",
    "                       epochs=5)\n",
    "        \n",
    "        train_time_end = time.time()\n",
    "        \n",
    "        self.train_time = train_time_end - train_time_start\n",
    "        \n",
    "    def test(self):\n",
    "        test_time_start = time.time()\n",
    "        test_loss, test_acc, test_f1, test_prec, test_recall = self.model.evaluate(self.X_test, self.Y_test, verbose=2)\n",
    "        test_time_end = time.time()\n",
    "        \n",
    "        self.test_time = test_time_end - test_time_start\n",
    "        self.acc = test_acc\n",
    "        self.f1 = test_f1\n",
    "        self.prec = test_prec\n",
    "        self.recall = test_recall\n",
    "        print(\"prediction accuracy: {:.2f}\".format(test_acc)) # 예측 정확도\n",
    "        \n",
    "    def save(self):\n",
    "        tm = time.localtime()\n",
    "        tm_string = time.strftime('%Y-%m-%d-%H_%M_%S', tm)\n",
    "        f = open('Encoder_Model'+tm_string+'.txt', 'w')\n",
    "        f.write('train time: ' + str(self.train_time)+'\\n')\n",
    "        f.write('test time: ' + str(self.test_time)+'\\n')\n",
    "        f.write('acc: ' + str(self.acc)+'\\n')\n",
    "        f.write('f1: ' + str(self.f1)+'\\n')\n",
    "        f.write('prec: ' + str(self.prec)+'\\n')\n",
    "        f.write('recall: ' + str(self.recall)+'\\n')\n",
    "        f.write('extract_list: ' + str(self.extract_list)+'\\n')\n",
    "        \n",
    "        self.model.save(\"Encoder_Model\"+tm_string)\n",
    "        \n",
    "encode1 = Encoder_Model(data1.input_len, data1.X_train, data1.X_test, data1.Y_train, data1.Y_test, data1.extract_list)\n",
    "encode1.train()\n",
    "encode1.test()\n",
    "encode1.save()\n",
    "\n",
    "encode2 = Encoder_Model(data2.input_len, data2.X_train, data2.X_test, data2.Y_train, data2.Y_test, data2.extract_list)\n",
    "encode2.train()\n",
    "encode2.test()\n",
    "encode2.save()\n",
    "\n",
    "encode3 = Encoder_Model(data3.input_len, data3.X_train, data3.X_test, data3.Y_train, data3.Y_test, data3.extract_list)\n",
    "encode3.train()\n",
    "encode3.test()\n",
    "encode3.save()\n",
    "\n",
    "encode4 = Encoder_Model(data4.input_len, data4.X_train, data4.X_test, data4.Y_train, data4.Y_test, data4.extract_list)\n",
    "encode4.train()\n",
    "encode4.test()\n",
    "encode4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
